{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proj2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/692-Team-1-NLP/proj-2/blob/main/proj2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKG2UOGSsk4j"
      },
      "source": [
        "# edit test- Addi \n",
        "#Author: Luke+Veronica\n",
        "#Description: Functions for retrieving and cleaning corpus\n",
        "import urllib.request, re\n",
        "\n",
        "# this function accepts a book title as a parameter and fetches the index based on the title \n",
        "def get_index(title):\n",
        "  last_reg=re.compile(r\"\\w+$\")\n",
        "  last_word=re.findall(last_reg,title)[0]\n",
        "  if last_word ==\"Links\":\n",
        "    #\"The Murder on the Links\"\n",
        "    index=1\n",
        "  elif last_word==\"Styles\":\n",
        "    #\"The Mysterious Affair at Styles\"\n",
        "    index=2\n",
        "  elif last_word==\"Adversary\":\n",
        "    #\"The Secret Adversary\"\n",
        "    index=3\n",
        "  elif last_word==\"Suit\":\n",
        "    #\"The Man in the Brown Suit\"\n",
        "    index=4\n",
        "  elif last_word==\"Chimneys\":\n",
        "    #\"The Secret of Chimneys\"\n",
        "    index=5\n",
        "  return index\n",
        "\n",
        "# this function accepts a book index as a parameter and fetches the title based on the index \n",
        "def get_title(index):\n",
        "  if index==1:\n",
        "    title='The Murder on the Links'\n",
        "  elif index==2:\n",
        "    title='The Mysterious Affair at Styles'\n",
        "  elif index==3:\n",
        "    title='The Secret Adversary'\n",
        "  elif index==4:\n",
        "    title='The Man in the Brown Suit'  \n",
        "  elif index==5:\n",
        "    title='The Secret of Chimneys'\n",
        "  return title\n",
        "\n",
        "# this function accepts a book index as a parameter and get the text for the book from project gutenberg \n",
        "def get_text(index):\n",
        "  if index==1:\n",
        "    #\"The Murder on the Links\"\n",
        "    url = \"https://www.gutenberg.org/files/58866/58866-0.txt\"\n",
        "  elif index==2:\n",
        "    #\"The Mysterious Affair at Styles\"\n",
        "    url=\"https://www.gutenberg.org/files/863/863-0.txt\"\n",
        "  elif index==3:\n",
        "    #\"The Secret Adversary\"\n",
        "    url=\"https://www.gutenberg.org/files/1155/1155-0.txt\"\n",
        "  elif index==4:\n",
        "    #\"The Man in the Brown Suit\"\n",
        "    url=\"https://www.gutenberg.org/files/61168/61168-0.txt\"\n",
        "  elif index==5:\n",
        "    #\"The Secret of Chimneys\"\n",
        "    url=\"https://www.gutenberg.org/files/65238/65238-0.txt\"\n",
        "  response = urllib.request.urlopen(url)\n",
        "  data = response.read()      # a `bytes` object\n",
        "  text = data.decode('utf-8')\n",
        "  return text\n",
        "\n",
        "\n",
        "# this function accepts a book index  and returns an appropriate regex that can carve out chapters for that book\n",
        "def get_ch_regex(index):\n",
        "  if index==1:\n",
        "    ch_carve=re.compile(r'\\n\\d\\d?\\s[\\'\\\"\\u201c]?[A-Z].*\\n')\n",
        "  elif index==2:\n",
        "    ch_carve=re.compile(r'CHAPTER\\s[IVX]+\\.\\r\\n.*\\r\\n')\n",
        "  elif index==3:\n",
        "    ch_carve=re.compile(r'\\r\\n\\r\\n\\r\\nCHAPTER.*\\r\\n')\n",
        "  elif index==4:\n",
        "    ch_carve=re.compile(r'CHAPTER\\s\\w+\\r\\n')  \n",
        "  elif index==5:\n",
        "    ch_carve=re.compile(r'\\d\\d?\\r\\n\\r\\n[A-OQ-Z].*\\r\\n')\n",
        "  return ch_carve\n",
        "\n",
        "\n",
        "# this function accepts a book index and chapter contents as parameters and trims out any Project gutenberg related artifacts that are not part of the novel\n",
        "def trim_contents(ch_contents_dict,index):\n",
        "  last=len(ch_contents_dict)\n",
        "  if index==1:\n",
        "    ch_contents_dict[last]=ch_contents_dict[last].split('\\nEnd of Project Gutenberg')[0]\n",
        "  elif index==2:\n",
        "    ch_contents_dict[last]=ch_contents_dict[last].split('\\nTHE END')[0]\n",
        "  elif index==3:\n",
        "    ch_contents_dict[last-1]=ch_contents_dict[last-1].split('\\nEnd of the Project Gutenberg')[0]\n",
        "  elif index==4:\n",
        "    ch_contents_dict[last-1]=ch_contents_dict[last-1].split('THE END')[0]\n",
        "  elif index==5:\n",
        "    ch_contents_dict[last]=re.split(r\"TRANSCRIBER\",ch_contents_dict[last])[0]\n",
        "  return ch_contents_dict\n",
        "\n",
        "\n",
        "# this function accepts chapter as a parameter and removes white spaces\n",
        "def remove_white(chapter):\n",
        "  regex=r'[\\r\\n\\u200a_]+'\n",
        "  chapter = re.sub(regex,' ',chapter)\n",
        "  return chapter\n",
        "\n",
        "\n",
        "# this function accepts chapter as a parameter and carves out sentences\n",
        "def sent_carve(chapter):\n",
        "  #chapter=re.split(r'(?<![A-H|J-Z])[\\.\\?!](?![\\'\\\"\\u2019\\u201a\\u201c\\u275c\\u275f\\u201e\\u201d\\u0022\\u275e]\\s[a-z])(?![\\'\\\"\\u2019\\u201a\\u201c\\u275c\\u275f\\u201e\\u201d\\u0022\\u275e]\\sI said)[\\'\\\"\\u2018\\u2019\\u201c\\u201d\\)\\]]*\\s*(?<!\\w\\.\\w)(?<![A-Z][a-z][a-z])(?<![A-Z][a-z])\\s+',chapter,flags=re.UNICODE)\n",
        "  chapter=re.split(r'(?<![^A-Z][A-H|J-Z])(?<!Mr|Ms|Dr)(?<!Mrs)(?<!Mlle)(?<!Melle)(?<!\\w\\.\\w)[\\.\\?!](?!\\.)(?![\\'\\\"\\u2019\\u201a\\u201c\\u275c\\u275f\\u201e\\u201d\\u0022\\u275e]\\s[a-z])[\\'\\\"\\u2018\\u2019\\u201c\\u201d\\)\\]]*\\s*|\\u2014\\u201d\\s*',chapter,flags=re.UNICODE)\n",
        "  chapter=chapter[:-1]\n",
        "  chapter={num+1:contents.lower() for (num,contents) in enumerate(chapter)}\n",
        "  return chapter\n",
        "\n",
        "\n",
        "# this function accepts a book title and carves out chapters and returns a dictionary of book title, chapter contents and chapter title\n",
        "def ch_carve(title):\n",
        "\n",
        "  index=get_index(title)\n",
        "  text=get_text(index)\n",
        "  ch_regex=get_ch_regex(index)\n",
        "  if index ==3:\n",
        "    text=re.split(\"CHAPTER XXVIII.     AND AFTER\\r\\n\\r\\n\\r\\n\\r\\nPROLOGUE\",text)[1]\n",
        "  if index ==4:\n",
        "    text=re.split(\"PROLOGUE\",text)[1]\n",
        "  ch_titles=re.findall(ch_regex,text)\n",
        "  ch_titles_dict={num+1:remove_white(title.strip()) for (num,title) in enumerate(ch_titles)}\n",
        "  if index==3 or index ==4:\n",
        "    ch_titles_dict.update( {0 :\"PROLOGUE\"} )\n",
        "  chapters=re.split(ch_regex,text)\n",
        "  if index==3 or index==4:\n",
        "    ch_contents_dict = {num:contents for (num,contents) in enumerate(chapters)}  \n",
        "  elif index ==1 or index ==2 or index==5:\n",
        "    chapters=chapters[1:]\n",
        "    ch_contents_dict = {num+1:contents for (num,contents) in enumerate(chapters)}\n",
        "  ch_contents_dict=trim_contents(ch_contents_dict,index)\n",
        "  return {\"title\":title,\"contents\":ch_contents_dict,\"chapters\":ch_titles_dict}\n",
        "\n",
        "\n",
        "# this function calls other helper functions and gets the corpus we will be working with\n",
        "def get_corpus():\n",
        "  #tentatively planning to index books from 1 to match chapters\n",
        "  titles=[\"The Mysterious Affair at Styles\",\"The Murder on the Links\",\"The Secret Adversary\",\"The Man in the Brown Suit\",\"The Secret of Chimneys\"]\n",
        "  corpus={ get_index(title):ch_carve(title) for title in titles}\n",
        "  return corpus\n",
        "\n",
        "\n",
        "# this function calls other helper functions and cleans the corpus\n",
        "def clean_corpus(corpus):\n",
        "  for keyb,value in corpus.items():\n",
        "    for  keyc,value in value[\"contents\"].items():\n",
        "      corpus[keyb][\"contents\"][keyc]=sent_carve(remove_white(value))\n",
        "    \n",
        "  return corpus\n",
        "\n",
        "\n",
        "# this function returns each chapter as a single blob of text\n",
        "def sent_blob(chapter):\n",
        "  temp=''  \n",
        "  #chapter=re.split(r'(?<![A-H|J-Z])[\\.\\?!](?![\\'\\\"\\u2019\\u201a\\u201c\\u275c\\u275f\\u201e\\u201d\\u0022\\u275e]\\s[a-z])(?![\\'\\\"\\u2019\\u201a\\u201c\\u275c\\u275f\\u201e\\u201d\\u0022\\u275e]\\sI said)[\\'\\\"\\u2018\\u2019\\u201c\\u201d\\)\\]]*\\s*(?<!\\w\\.\\w)(?<![A-Z][a-z][a-z])(?<![A-Z][a-z])\\s+',chapter,flags=re.UNICODE)\n",
        "  chapter=re.split(r'(?<![^A-Z][A-H|J-Z])(?<!Mr|Ms|Dr)(?<!Mrs)(?<!Mlle)(?<!Melle)(?<!\\w\\.\\w)[\\.\\?!](?!\\.)(?![\\'\\\"\\u2019\\u201a\\u201c\\u275c\\u275f\\u201e\\u201d\\u0022\\u275e]\\s[a-z])[\\'\\\"\\u2018\\u2019\\u201c\\u201d\\)\\]]*\\s*|\\u2014\\u201d\\s*',chapter,flags=re.UNICODE)\n",
        "  chapter=chapter[:-1]\n",
        "  for ch in chapter:\n",
        "    temp=temp+\" \"+ch.lower()+\"#\"    \n",
        "  return temp\n",
        "\n",
        "\n",
        "# this function removes punctuation \n",
        "def remove_punc(blob):\n",
        "  blob=re.sub(r\"[\\u201c\\u201d\\?,;:\\.!\\u2018\\u2019\\u201a\\u275b\\u275c\\u275f\\s-]+\" ,' ',blob)\n",
        "  return blob\n",
        "def tighten(blob):\n",
        "  blob= re.sub(r\"\\s+\",\" \",blob)\n",
        "  blob=re.sub(r\"#\",\"\\n\",blob)\n",
        "  return blob\n",
        "\n",
        "# this function adds a dictionary to the corpus that contains each book as a single blob of test accessed via corpus[\"blob\"]\n",
        "def blob_corpus(dirty_corpus):\n",
        "  for keyb,value in dirty_corpus.items():\n",
        "    blob=''\n",
        "    for  keyc,value in value[\"contents\"].items():\n",
        "      blob=blob+\" \"+tighten(remove_punc(remove_white(sent_blob(dirty_corpus[keyb][\"contents\"][keyc]))))\n",
        "    dirty_corpus[keyb][\"blob\"]=blob  \n",
        "  return dirty_corpus"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxojzofRn9N2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBzLUiFsrBn"
      },
      "source": [
        "dirty_corpus=get_corpus()\n",
        "dirty_corpus=blob_corpus(dirty_corpus)\n",
        "corpus=clean_corpus(dirty_corpus)\n",
        "big_blob=corpus[1][\"blob\"]+corpus[2][\"blob\"]+corpus[3][\"blob\"]+corpus[4][\"blob\"]+corpus[5][\"blob\"]\n",
        "#print(big_blob)\n",
        "with open(\"temp.txt\",\"w\") as f:\n",
        "  f.write(big_blob)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL8T1WZN41KF",
        "outputId": "316f3650-71b1-4c26-fd8a-a9d75e3d636a"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wdccMYVsu-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9f08fd-e326-4743-97da-ce48a889618a"
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim import utils\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "class Corpus():\n",
        "  def __init__(self,path):\n",
        "    self.path=path\n",
        "  def __iter__(self):\n",
        "    corpus_path=datapath(self.path)\n",
        "    for line in open(corpus_path):\n",
        "      yield utils.simple_preprocess(remove_stopwords(line))\n",
        "path='/content/temp.txt'\n",
        "!pwd\n",
        "corpus=Corpus(path)\n",
        "model=Word2Vec(corpus)\n",
        "model.wv.most_similar('hercule')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('satisfied', 0.9963435530662537),\n",
              " ('figure', 0.9962856769561768),\n",
              " ('inclined', 0.9962761998176575),\n",
              " ('connection', 0.9962567090988159),\n",
              " ('easily', 0.9962537288665771),\n",
              " ('lips', 0.9962407350540161),\n",
              " ('paused', 0.9962387084960938),\n",
              " ('ears', 0.9962373375892639),\n",
              " ('somewhat', 0.9962337017059326),\n",
              " ('deep', 0.9962244033813477)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trrbakT_t60D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3eb02d-eb5c-42da-fe5e-4f986d069e34"
      },
      "source": [
        "\n",
        "model.wv.most_similar('poirot')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tommy', 0.9984163641929626),\n",
              " ('virginia', 0.9978669285774231),\n",
              " ('julius', 0.997782289981842),\n",
              " ('tuppence', 0.9974542856216431),\n",
              " ('anthony', 0.9969242215156555),\n",
              " ('slowly', 0.996880829334259),\n",
              " ('gently', 0.9967830181121826),\n",
              " ('thoughtfully', 0.9966556429862976),\n",
              " ('surprise', 0.9964278936386108),\n",
              " ('smile', 0.9962503910064697)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTl5IL9xk7ow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310f1358-12b8-4fc2-d867-75ed307f9d15"
      },
      "source": [
        "#spacy install\n",
        "!pip install spacy\n",
        "!python3 -m spacy download en_core_web_sm"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-TmRRpkn_d0"
      },
      "source": [
        "#spacy code\n",
        "from spacy.lang.en import English \n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# W.I.P.\n",
        "import re\n",
        "\n",
        "dirty_corpus=get_corpus()\n",
        "all_sentences=''\n",
        "for bookid in range(1,6):\n",
        "    nch=len(dirty_corpus[bookid][\"chapters\"])\n",
        "    for chid in range(1,nch):\n",
        "        dirty_chapter=dirty_corpus[bookid][\"contents\"][chid]\n",
        "        ch_doc = nlp(dirty_chapter)\n",
        "        ch_sentences=''\n",
        "        for sent in ch_doc.sents:\n",
        "          sent=re.sub(r\"\\s+\",' ',re.sub(r\"[\\u2000-\\u206F!\\\"#\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}~]+\",' ',sent.text.strip())).lower().strip()\n",
        "          if sent!=\"\":\n",
        "            ch_sentences+=sent+\"\\n\"\n",
        "    all_sentences+=ch_sentences\n",
        "print(all_sentences)\n",
        "with open(\"temp2.txt\",\"w\") as f:\n",
        "  f.write(all_sentences)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6rgvv1H7mlR"
      },
      "source": [
        "dirty_corpus=get_corpus()\n",
        "# this function adds a dictionary to the corpus that contains each book as a single blob of test accessed via corpus[\"blob\"]\n",
        "def sent_blob2(chapter):\n",
        "  temp=''  \n",
        "  ch_doc=nlp(chapter)\n",
        "  for sent in ch_doc.sents:\n",
        "    sent=re.sub(r\"\\s+\",' ',re.sub(r\"[\\u2000-\\u206F!\\\"#\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}~]+\",' ',sent.text.strip())).lower().strip()\n",
        "    if sent!=\"\":\n",
        "      temp+=sent+\"\\n\"    \n",
        "  return temp\n",
        "\n",
        "def blob_corpus2(dirty_corpus):\n",
        "  for keyb,value in dirty_corpus.items():\n",
        "    blob=''\n",
        "    for  keyc,value in value[\"contents\"].items():\n",
        "      blob+=sent_blob2(dirty_corpus[keyb][\"contents\"][keyc])\n",
        "    dirty_corpus[keyb][\"blob\"]=blob  \n",
        "  return dirty_corpus\n",
        "c2=blob_corpus2(dirty_corpus)\n",
        "blob2=c2[1][\"blob\"]+c2[2][\"blob\"]+c2[3][\"blob\"]+c2[4][\"blob\"]+c2[5][\"blob\"]\n",
        "with open(\"temp2.txt\",\"w\") as f:\n",
        "  f.write(blob2)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmbbgD2p5MLS",
        "outputId": "f4fd7c9e-594b-4b46-9ee0-92739ebb80cc"
      },
      "source": [
        "path='/content/temp2.txt'\n",
        "!pwd\n",
        "scapy_corpus=Corpus(path)\n",
        "sc_model=Word2Vec(scapy_corpus)\n",
        "sc_model.wv.most_similar('hercule')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('replied', 0.9969497323036194),\n",
              " ('asked', 0.9968485236167908),\n",
              " ('sat', 0.9967306852340698),\n",
              " ('stared', 0.9966945052146912),\n",
              " ('walked', 0.9966557025909424),\n",
              " ('surprise', 0.9966446757316589),\n",
              " ('continued', 0.9966220855712891),\n",
              " ('smiled', 0.9966018795967102),\n",
              " ('stepped', 0.9965628981590271),\n",
              " ('felt', 0.9965613484382629)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAJpJ8Q_n_0D"
      },
      "source": [
        "Test-Addi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKqpYKsXoUtB",
        "outputId": "85a79b7d-6af1-4d6e-9acd-9f34bf35cfc7"
      },
      "source": [
        "print(\"Test\")\n",
        "print(\"foo\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test\n",
            "foo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgIIrTMeodSk"
      },
      "source": [
        "This is some text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1glp5dGpHBQ"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}